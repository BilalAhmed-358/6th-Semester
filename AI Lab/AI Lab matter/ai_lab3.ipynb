{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["wKEptYPbIAuh","P6s9VEI6M9xf","8z0R4pD4zp7s","Clan4Ee0ztan","Dne9ba_x3mJj","j6evaD9089-o","TlSECDLp-zcM"],"authorship_tag":"ABX9TyMWrB/XAJg6r0+eByLW3H+o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# AI Lab 3 - Intelligent Agent\n","Saad Bin Khalid<br>\n","20K-0161<br>\n","BSCS-6F"],"metadata":{"id":"3lCt9aGP7QAX"}},{"cell_type":"markdown","source":["## **Task 1:** &emsp; Distance Monitoring Robot\n","Consider an interactive and cognitive environment (ICE) in which a smart camera is monitoring robot movement from one location to another. Let a robot be at location A for some time instant and then moves to point B and eventually reaches at point C and so on and so forth shown in the Fig. Develop a Python code to calculate a distance between reference point R (4, 0) of a camera and A, B, and C and N number of locations."],"metadata":{"id":"wKEptYPbIAuh"}},{"cell_type":"code","source":["from random import randint \n","from time import sleep\n","from IPython.display import clear_output"],"metadata":{"id":"h6TrlwHwGS7I","executionInfo":{"status":"ok","timestamp":1676228938199,"user_tz":-300,"elapsed":5,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def distance(p1, p2):\n","  xx = p1[0] - p2[0]\n","  yy = p1[1] - p2[1]\n","  xx = xx ** 2\n","  yy = yy ** 2\n","  dist = (xx + yy) ** 0.5\n","  return round(dist, 2)"],"metadata":{"id":"eESazvs0GUFY","executionInfo":{"status":"ok","timestamp":1676228938200,"user_tz":-300,"elapsed":5,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def print_maze(maze):\n","  for row in maze:\n","    for x in row:\n","      print(x, end=\" \")\n","    print()"],"metadata":{"id":"JJHl4gOYG7wB","executionInfo":{"status":"ok","timestamp":1676228938200,"user_tz":-300,"elapsed":5,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["maze = []\n","ref = (4, 0)\n","\n","for i in range(10):\n","  maze.append( ['-' for i in range(10)] )\n","maze[ref[0]][ref[1]] = '@'"],"metadata":{"id":"Z772PBoJG-Bg","executionInfo":{"status":"ok","timestamp":1676228938201,"user_tz":-300,"elapsed":5,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrpjzW8D65RT","outputId":"97339a34-aba7-429b-e0c1-eb85d37ffc31","executionInfo":{"status":"ok","timestamp":1676228953591,"user_tz":-300,"elapsed":15395,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["- R - - - - - - - - \n","- - - - - - - - - - \n","- - - - - - - - - - \n","- - - - - - - - - - \n","@ - - - - - - - - - \n","- - - - - - - - - - \n","- - - - - - - - - - \n","- - - - - - - - - - \n","- - - - - - - - - - \n","- - - - - - - - - - \n","\n","4.12  units\n"]}],"source":["x = 0\n","y = 0\n","for i in range(10):\n","  maze[x][y] = '-'\n","  x = randint(0,9)\n","  y = randint(0,9)\n","  maze[x][y] = 'R'\n","  \n","  sleep(1.5)\n","  clear_output()\n","  print_maze(maze)\n","  print()\n","  print(distance(ref, (x,y)), ' units')"]},{"cell_type":"markdown","source":["## **Task 2:** &emsp; Obstacle Avoiding Car\n","Consider a scenario, cameras placed on every side of the car — front, rear, left and right — to stitch together a 360-degree view of the environment. For a three-lane road a car is moving on a middle lane, consider the below scenario.\n","\n","* If the front camera detects the object within range of 8 meters breaks are \n","applied automatically.\n","* If the left camera detects the object within range of 2 meters car moves to the right lane.\n","* If the right camera detects the object within range of 2 meters car moves to the left lane.\n","* For parking the car if the rear camera detects the object within 5 cm breaks are applied."],"metadata":{"id":"P6s9VEI6M9xf"}},{"cell_type":"code","source":["front_camera_range = 8\n","side_camera_range = 2\n","rear_camera_range = 0.05"],"metadata":{"id":"Me3imI0MyVdr","executionInfo":{"status":"ok","timestamp":1676228953592,"user_tz":-300,"elapsed":29,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def monitor_surroundings(camera_position, distance_to_object):\n","  if camera_position == \"front\":\n","      if distance_to_object <= front_camera_range:\n","          print(\"Brakes applied\")\n","  elif camera_position == \"left\":\n","      if distance_to_object <= side_camera_range:\n","          print(\"Changing lane to right\")\n","  elif camera_position == \"right\":\n","      if distance_to_object <= side_camera_range:\n","          print(\"Changing lane to left\")\n","  elif camera_position == \"rear\":\n","      if distance_to_object <= rear_camera_range:\n","          print(\"Brakes applied\")"],"metadata":{"id":"RUIEiKKq4SIE","executionInfo":{"status":"ok","timestamp":1676228953592,"user_tz":-300,"elapsed":28,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["monitor_surroundings(\"front\", 2)\n","monitor_surroundings(\"left\", 1)\n","monitor_surroundings(\"right\", 5)\n","monitor_surroundings(\"rear\", 0.4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCkc_5jUr7cA","executionInfo":{"status":"ok","timestamp":1676228953593,"user_tz":-300,"elapsed":28,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}},"outputId":"d0dfe23f-0461-40aa-a019-b8590d268b56"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Brakes applied\n","Changing lane to right\n"]}]},{"cell_type":"markdown","source":["## **Task 3:** &emsp; UAV temperatures\n","\n","Consider the following scenario where the UAV receives temperature data from the installed sensors in a residential area. Assume that there are nine sensors installed that are measuring temperature in centigrade. Develop a Python code to calculate the average temperature in F."],"metadata":{"id":"8z0R4pD4zp7s"}},{"cell_type":"code","source":["import random\n","\n","temperatures = []\n","n = 9\n","num_iterations = 10\n","\n","for i in range(num_iterations):\n","    for j in range(n):\n","        temperature = random.uniform(10, 40)\n","        temperatures.append(temperature)\n","    \n","    avg_temp = sum(temperatures) / n\n","    avg_temp_f = (avg_temp * 9/5) + 32\n","    \n","    print(f\"Reading {i+1}: Average temperature is {avg_temp_f:.2f}°F\")\n","    temperatures.clear()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7NUKCDC1LXE","executionInfo":{"status":"ok","timestamp":1676228953593,"user_tz":-300,"elapsed":27,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}},"outputId":"4e855951-14d8-41d2-de73-a9183209005a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading 1: Average temperature is 74.82°F\n","Reading 2: Average temperature is 74.16°F\n","Reading 3: Average temperature is 82.38°F\n","Reading 4: Average temperature is 68.25°F\n","Reading 5: Average temperature is 76.87°F\n","Reading 6: Average temperature is 81.47°F\n","Reading 7: Average temperature is 79.04°F\n","Reading 8: Average temperature is 83.38°F\n","Reading 9: Average temperature is 68.20°F\n","Reading 10: Average temperature is 81.03°F\n"]}]},{"cell_type":"markdown","source":["## **Task 4** &emsp; Automatic Vacuum Cleaner\n","\n","An AI startup has approached you to write a program for their automatic vacuum cleaner. or the vacuum cleaner the room appears to be a matrix of n * m. Each index referred to as a cell of the matrix is valued as dirty “D”, clean “C”. The cells which are occupied by the stuff in the room are blocked and valued “B”. The vacuum can move in all four directions (up, down, left, right), and if the cell status is D, it will clean the cell and change the status to “C”, if the cell status is either C, it will not enter the cell. The vacuum will stop working if the surrounding of its positions is cleaned (Up, Left, Right, Down), i.e., the status of all the cells is either C. The vacuum may start cleaning the room from the first cell (0, 0) or any random location. You will trace the path of the vacuum and display at the end of the program."],"metadata":{"id":"Clan4Ee0ztan"}},{"cell_type":"code","source":["room = [\n","        ['B', 'D', 'B'],\n","        ['D', 'C', 'D'],\n","        ['D', 'D', 'D'],\n","        ['D', 'B', 'D']\n","      ]\n","      \n","directions = [\n","                (0, 1), \n","                (1, 0), \n","                (0, -1), \n","                (-1, 0)\n","            ]"],"metadata":{"id":"iXaYiH6G1RBN","executionInfo":{"status":"ok","timestamp":1676228953594,"user_tz":-300,"elapsed":27,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def is_valid_x(x): return 0 <= x < len(room)\n","def is_valid_y(y): return 0 <= y < len(room[0])\n","\n","def backtrack(x, y, direction_index):\n","  if room[x][y] == \"D\":\n","      room[x][y] = \"C\"\n","      \n","  for dx, dy in directions[direction_index:] + directions[:direction_index]:\n","      new_x = x + dx\n","      new_y = y + dy\n","      is_valid_indexes = is_valid_x(new_x) and is_valid_y(new_y)\n","\n","      if (is_valid_indexes and room[new_x][new_y] != \"C\"):\n","          backtrack(new_x, new_y, 0)\n","\n","backtrack(0, 0, 0)\n","for row in room:\n","  print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3M3ozbVz-hA","executionInfo":{"status":"ok","timestamp":1676228953594,"user_tz":-300,"elapsed":27,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}},"outputId":"f1b0e512-4f1c-4648-9dd3-0ff7e633bcf2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['B', 'C', 'B']\n","['C', 'C', 'C']\n","['C', 'C', 'C']\n","['C', 'B', 'C']\n"]}]},{"cell_type":"markdown","source":["## **Task 5** &emsp; Tic Tac Toe with Computer Agent\n","\n","Write a program for a tic tac toe game for a single-player game, in this program user plays against a computer agent. computer agent and player get multiple chances to mark their respective symbol on the empty spaces of the grid. The goal of the computer agent is to win the game. You can assign (X or O) to a computer agent. On every move, the computer must strike its marking where necessary to win the game. If there is no winning move on any strike\n","then the computer marks anywhere on the board.\n"],"metadata":{"id":"Dne9ba_x3mJj"}},{"cell_type":"code","source":["board = [\n","          [' ', ' ', ' '],\n","          [' ', ' ', ' '],\n","          [' ', ' ', ' ']\n","      ]\n","\n","human, computer = 'X', 'O'"],"metadata":{"id":"GfJvKkkA4AAY","executionInfo":{"status":"ok","timestamp":1676228953595,"user_tz":-300,"elapsed":16,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def print_board():\n","    print(\"\\n\")\n","    for row in board:\n","        print(\" \".join(row))\n","    print(\"\\n\")"],"metadata":{"id":"2MIFFZau4osW","executionInfo":{"status":"ok","timestamp":1676228953595,"user_tz":-300,"elapsed":16,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def check_win(player):\n","    # check rows\n","    for row in board:\n","        if row == [player, player, player]:\n","            return True\n","    # check columns\n","    for col in range(3):\n","        if (board[0][col] == player and\n","            board[1][col] == player and\n","            board[2][col] == player):\n","            return True\n","    \n","    # check diagonals\n","    if (board[0][0] == player and\n","        board[1][1] == player and\n","        board[2][2] == player):\n","        return True\n","    \n","    if (board[0][2] == player and\n","        board[1][1] == player and\n","        board[2][0] == player):\n","        return True\n","    return False"],"metadata":{"id":"wYCWIF4m429f","executionInfo":{"status":"ok","timestamp":1676228953596,"user_tz":-300,"elapsed":16,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def get_move_computer():\n","    # Check if computer can win in the next move\n","    for row in range(3):\n","        for col in range(3):\n","            if board[row][col] == ' ':\n","                board[row][col] = computer\n","                if check_win(computer):\n","                    return\n","                board[row][col] = ' '\n","\n","    # Check if human can win in the next move\n","    for row in range(3):\n","        for col in range(3):\n","            if board[row][col] == ' ':\n","                board[row][col] = human\n","                if check_win(human):\n","                    board[row][col] = computer\n","                    return\n","                board[row][col] = ' '\n","                \n","    # Play random move\n","    for row in range(3):\n","        for col in range(3):\n","            if board[row][col] == ' ':\n","                board[row][col] = computer\n","                return"],"metadata":{"id":"u8rTrLKE5Oe-","executionInfo":{"status":"ok","timestamp":1676228953596,"user_tz":-300,"elapsed":16,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def get_move_human():\n","    print(\"Your turn\")\n","    row = int(input(\"Enter row (0, 1, 2): \"))\n","    col = int(input(\"Enter column (0, 1, 2): \"))\n","    \n","    if board[row][col] == ' ':\n","        board[row][col] = human\n","    else:\n","        print(\"The cell is already occupied. Try again.\")\n","        get_move_human()"],"metadata":{"id":"DeU0Am-X5Yo2","executionInfo":{"status":"ok","timestamp":1676228953598,"user_tz":-300,"elapsed":17,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","print_board()\n","\n","for move in range(9):\n","    if move % 2 == 0:\n","        get_move_human()\n","    else:\n","        get_move_computer()\n","\n","    print_board()\n","\n","    if check_win(human):\n","        print(\"You win!\")\n","        break\n","    if check_win(computer):\n","        print(\"Computer wins!\")\n","        break\n","\n","if not check_win(human) and not check_win(computer):\n","    print(\"It's a draw.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VK89Fpn3iXK","executionInfo":{"status":"ok","timestamp":1676228990761,"user_tz":-300,"elapsed":22310,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}},"outputId":"0070d585-45a5-416e-e136-45ed0b8578bc"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","     \n","     \n","     \n","\n","\n","Your turn\n","Enter row (0, 1, 2): 0\n","Enter column (0, 1, 2): 0\n","\n","\n","X    \n","     \n","     \n","\n","\n","\n","\n","X O  \n","     \n","     \n","\n","\n","Your turn\n","Enter row (0, 1, 2): 1\n","Enter column (0, 1, 2): 0\n","\n","\n","X O  \n","X    \n","     \n","\n","\n","\n","\n","X O  \n","X    \n","O    \n","\n","\n","Your turn\n","Enter row (0, 1, 2): 1\n","Enter column (0, 1, 2): 1\n","\n","\n","X O  \n","X X  \n","O    \n","\n","\n","\n","\n","X O  \n","X X O\n","O    \n","\n","\n","Your turn\n","Enter row (0, 1, 2): 2\n","Enter column (0, 1, 2): 2\n","\n","\n","X O  \n","X X O\n","O   X\n","\n","\n","You win!\n"]}]},{"cell_type":"markdown","source":["## **Task 6** &emsp; Shortest Path between cities\n","\n","Your task is to write a program of utility-based agent that find the best route (minimum Distance, shortest path) from source to destination node."],"metadata":{"id":"j6evaD9089-o"}},{"cell_type":"code","source":["graph = {\n","    'Fast NU':  {'Karsaz':15, 'Gulshen':30, 'Korangi':20},\n","    'Karsaz':   {'Fast NU':15, 'Gulshen':8, 'Sadar':10, 'Korangi':10},\n","    'Gulshen':  {'Karsaz':8, 'Sadar':20, 'Fast NU':30, 'Korangi':1},\n","    'Sadar':    {'Gulshen':20, 'Korangi':10, 'Karsaz':10},\n","    'Korangi':  {'Sadar':10, 'Gulshen':1, 'Fast NU':20, 'Karsaz':10}\n","}"],"metadata":{"id":"AJ8wcECJ-1jz","executionInfo":{"status":"ok","timestamp":1676229028848,"user_tz":-300,"elapsed":402,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import heapq\n","\n","def dijkstra(graph, start):\n","    distances = {node: float('inf') for node in graph}\n","    distances[start] = 0\n","    \n","    heap = [(0, start)]\n","    while heap:\n","        dist, current = heapq.heappop(heap)\n","        if dist > distances[current]:\n","            continue\n","\n","        for neighbor, weight in graph[current].items():\n","            distance = dist + weight\n","            if distance < distances[neighbor]:\n","                distances[neighbor] = distance\n","                heapq.heappush(heap, (distance, neighbor))\n","    return distances"],"metadata":{"id":"Nut19cEL9E4A","executionInfo":{"status":"ok","timestamp":1676229030760,"user_tz":-300,"elapsed":2,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["distances = dijkstra(graph, 'Fast NU')\n","print(distances)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E57Z9Q0GCWum","executionInfo":{"status":"ok","timestamp":1676229096477,"user_tz":-300,"elapsed":5,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"}},"outputId":"47def4ce-fbe4-4577-f8d1-c897d3eff184"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Fast NU': 0, 'Karsaz': 15, 'Gulshen': 21, 'Sadar': 25, 'Korangi': 20}\n"]}]},{"cell_type":"markdown","source":["## **Task 7** &emsp; Learning Agent\n","\n","How you can transform task 04, 05 and 06 into learning agent."],"metadata":{"id":"TlSECDLp-zcM"}},{"cell_type":"markdown","source":["### **Task 4** &emsp; Automatic Vacuum Cleaner\n","\n","* **Create a memory store:** The agent will keep track of the rooms it has cleaned and the paths it has taken. This memory store can be implemented as a database or a simple data structure like a list or a dictionary.\n","\n","* **Add a reward system:** The agent will receive a reward for successfully cleaning the room and a penalty for not cleaning all the dirt. The rewards and penalties can be positive or negative numbers.\n","\n","* **Train the agent:** The agent will be trained by running multiple simulations of the vacuum cleaning task. During each simulation, the agent will take an action and receive a reward based on its performance. The agent will use this feedback to update its decision-making processes.\n","\n","* **Implement a machine learning algorithm:** The agent can be trained using various machine learning algorithms such as reinforcement learning, Q-learning, or supervised learning.\n","\n","* **Update the decision-making process:** The agent will use the information stored in its memory store and the outputs of the machine learning algorithm to make decisions about which actions to take in the future.\n","\n","* **Evaluate the agent's performance:** The agent's performance can be evaluated by running additional simulations and comparing the results to the initial performance of the agent. Over time, the agent should demonstrate improved performance as it continues to learn and improve its decision-making processes."],"metadata":{"id":"QVu5nM-W_vGW"}},{"cell_type":"markdown","source":["### **Task 5** &emsp; Tic Tac Toe with Computer Agent\n","\n","* **Create a state representation:** Represent the Tic Tac Toe board as a matrix with cells containing either X, O, or a blank.\n","\n","* **Define the reward system:** The agent should receive a positive reward for winning the game, a negative reward for losing the game, and a small positive reward for making a good move.\n","\n","* **Train the agent:** The agent can be trained by playing multiple games against itself. The agent will take an action in each game, receive a reward based on its performance, and update its decision-making process accordingly.\n","\n","* **Implement a reinforcement learning algorithm:** You can use a reinforcement learning algorithm like Q-learning or SARSA to train the agent.\n","\n","* **Update the decision-making process:** The agent should use the information stored in its memory and the outputs of the reinforcement learning algorithm to make decisions about which actions to take in each game.\n","\n","* **Evaluate the agent's performance:** The performance of the agent can be evaluated by comparing the results of games against a random agent or a fixed strategy agent. Over time, the agent should demonstrate improved performance as it continues to learn and improve its decision-making process."],"metadata":{"id":"mCuh270yAo8A"}},{"cell_type":"markdown","source":["### **Task 6** &emsp; Shortest Path Between Cities\n","\n","Transforming the Dijkstra algorithm program into a learning agent is not straightforward because Dijkstra's algorithm is a shortest path finding algorithm and it does not inherently involve learning or decision making.\n","\n","\n","* **Supervised learning:** You can use supervised learning to train a model to predict the shortest path between two nodes in a graph. You would need to gather a dataset of graphs and corresponding shortest path information and use that data to train a model. The model could then be used to predict the shortest path in new graphs.\n","\n","* **Reinforcement learning:** You can consider using reinforcement learning if the graph changes dynamically over time and the agent needs to learn how to find the shortest path in real-time. The agent could be trained to learn a policy that maps states (representing the current state of the graph) to actions (representing the next node to visit in the shortest path). The agent would receive a reward for reaching the destination node and update its policy accordingly."],"metadata":{"id":"LWynwEl3Blnn"}}]}