{"cells":[{"cell_type":"markdown","metadata":{"id":"dRlPQ0SmSaA2"},"source":["# AI Lab 11 - Reinforcement Learning\n","Saad Bin Khalid<br>\n","20K-0161<br>\n","BSCS-6F"]},{"cell_type":"markdown","metadata":{"id":"tXWqXngjTEFU"},"source":["## **Task 1:** &emsp;  Q Learning Algorithm"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683734203101,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"whGWT4rwU_u5"},"outputs":[],"source":["# constants\n","\n","n = 10000\n","steps = 100\n","exploration_rate = 1.0\n","\n","learning_rate = 0.8\n","discount_rate = 0.95\n","decay_rate = 0.001\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683734205366,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"EvZBh82TVJp-","outputId":"fb611f3d-2463-4a87-a01b-b5db449911c7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["# environment and table\n","\n","import gym\n","import numpy as np\n","\n","env = gym.make('FrozenLake-v1')\n","\n","n_action = env.action_space.n\n","n_state = env.observation_space.n\n","q_table = np.zeros((n_state, n_action))"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8032,"status":"ok","timestamp":1683734215699,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"E_0bUwyMSWQ_","outputId":"a1788b52-5b39-48f0-b54d-9370463d6caa"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.44571684e-01 5.12090208e-02 5.92431519e-02 6.96367552e-02]\n"," [2.14109782e-02 1.17813923e-02 7.36839420e-03 3.12865125e-02]\n"," [2.85294596e-02 2.69606625e-02 2.77825533e-02 2.84816380e-02]\n"," [5.38371922e-03 1.44057552e-03 4.77263438e-03 2.63410013e-02]\n"," [3.11489435e-01 6.61738536e-02 9.89846004e-03 1.25731747e-01]\n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"," [1.21122564e-05 4.62602491e-01 1.01310904e-02 3.92296755e-03]\n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"," [4.62848383e-02 9.58839286e-03 4.20574458e-02 2.14142117e-01]\n"," [6.48275482e-02 6.75883425e-01 1.45138127e-02 1.28807686e-03]\n"," [1.72252013e-02 7.76433230e-01 5.10233486e-04 2.56076726e-02]\n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"," [9.84537071e-02 9.19910282e-01 5.85294691e-01 9.27152773e-02]\n"," [6.31107987e-01 7.18582253e-01 6.48179852e-01 9.99599684e-01]\n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"]}],"source":["# q-learning algorithm\n","\n","for episode in range(n):\n","    step = 0\n","    done = False\n","    state = env.reset()\n","    \n","    for i in range(steps):\n","        if np.random.uniform(0, 1) > exploration_rate:\n","            action = np.argmax(q_table[state,:])\n","        else:\n","            action = env.action_space.sample()\n","        new_state, reward, done, _ = env.step(action)\n","        \n","        old_table = q_table[state, action]\n","        max_val = np.max(q_table[new_state, :])\n","        q_table[state, action] = old_table + learning_rate * (reward + discount_rate * max_val - old_table)\n","\n","        state = new_state\n","        if done == True: break\n","\n","    exploration_rate = 0.1 + (1 - 0.1) * np.exp(-decay_rate * episode)\n","\n","env.close()\n","print(q_table)"]},{"cell_type":"markdown","metadata":{"id":"UYt6iUNDWCyf"},"source":["## **Task 2:** &emsp;  Smart Cab's Job"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683734339988,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"WFctkKU3WN0e"},"outputs":[],"source":["# constants\n","\n","n = 1000\n","steps = 99\n","exploration_rate = 1.0\n","\n","learning_rate = 0.7\n","discount_rate = 0.9\n","decay_rate = 0.001"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683734527947,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"4AqI-KJGVZiL","outputId":"4e2cb52b-b4a8-4a95-837d-047942ee6a2c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["# environment\n","\n","import os\n","import gym\n","import pygame\n","import random\n","import numpy as np\n","\n","os.environ['SDL_VIDEODRIVER']='dummy'\n","pygame.display.set_mode((640,480))\n","env = gym.make('Taxi-v3')\n","\n","n_action = env.action_space.n\n","n_state = env.observation_space.n\n","q_table = np.zeros((n_state, n_action))"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":4072,"status":"ok","timestamp":1683734534268,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"Y3KqNymMS4CV"},"outputs":[],"source":["# q learning algorithm\n","\n","for episode in range(n):\n","    done = False\n","    state = env.reset()\n","\n","    for i in range(steps):\n","        if np.random.uniform(0, 1) > exploration_rate:\n","            action = np.argmax(q_table[state,:])\n","        else:\n","            action = env.action_space.sample()            \n","        new_state, reward, done, _ = env.step(action)\n","\n","        old_table = q_table[state, action]\n","        max_val = np.max(q_table[new_state, :])\n","        q_table[state, action] = old_table + learning_rate * (reward + discount_rate * max_val - old_table)\n","\n","        state = new_state\n","        if done == True: break\n","\n","    exploration_rate = np.exp(-decay_rate * episode)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3832,"status":"ok","timestamp":1683734540600,"user":{"displayName":"k200161 Saad Bin Khalid","userId":"08938229604629399021"},"user_tz":-300},"id":"vaiVtKitZFyk","outputId":"89574d93-b15f-4baf-e23e-79ed4aecb07f"},"outputs":[{"name":"stdout","output_type":"stream","text":["state:\n","114\n","1 ) score:  -1\n","2 ) score:  -2\n","3 ) score:  -3\n","4 ) score:  -4\n","5 ) score:  -5\n","6 ) score:  -6\n","7 ) score:  -7\n","8 ) score:  -8\n","9 ) score:  -9\n","10 ) score:  -10\n","11 ) score:  -11\n","12 ) score:  -12\n","13 ) score:  -13\n","14 ) score:  -14\n","15 ) score:  6\n"]}],"source":["# execution\n","\n","rewards = 0\n","done = False\n","state = env.reset()\n","print(\"state:\")\n","print(state)\n","\n","for i in range(steps):\n","    action = np.argmax(q_table[state,:])\n","    new_state, reward, done, _ = env.step(action)\n","    rewards += reward\n","    env.render()\n","\n","    print(i+1, \") score: \", rewards)\n","    state = new_state\n","    if done == True: break"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPiuuvyOY+4JzdS/wIfuGdf","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
